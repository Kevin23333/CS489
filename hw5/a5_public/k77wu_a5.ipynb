{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# A5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The code below creates two lists:\n",
    "  - `sentences`, and\n",
    "  - `next_chars`\n",
    "  \n",
    "Each list element represents a sequences of characters. There are 3 ways to represent a character:\n",
    "1. As a string, eg. `'b'`\n",
    "2. As an index to a character set, eg. `2`\n",
    "3. As a one-hot vector, eg. `[0, 0, 1, 0, ...]`\n",
    "\n",
    "The lists `sentences` and `next_chars` store the characters as indices. The utility functions\n",
    "  - `char2vec`\n",
    "  - `index2vec`\n",
    "  - `vec2char`\n",
    "  - `vec2index`\n",
    "  \n",
    "transform the characters between the 3 representations. You can also use the dictionaries `char_indices` and `indices_char` to convert between a string character and and index. The code below contains some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character set:  abcdefghijklmnopqrstuvwxyz (first char is a space)\n",
      "There are 27 characters in our character set\n",
      "Here is how you can view one of the samples:\n",
      "Sample input: [on the ori]\n",
      " the origi\n",
      "the origin\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = open('origin_of_species.txt').read().lower()\n",
    "chars = sorted(list(set(text)))\n",
    "chars.insert(0, \"\\0\") #Add newline character\n",
    "vocab_size = len(chars)\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "# Let's simplify it by keeping only letters and spaces\n",
    "filt_idx = []\n",
    "for i in idx:\n",
    "    if i<=24:\n",
    "        filt_idx.append(2)\n",
    "    elif i>24:\n",
    "        filt_idx.append(i)\n",
    "blah = ''.join([indices_char[f] for f in filt_idx])\n",
    "text = re.sub(' +', ' ', blah)\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print('Character set: '+''.join(chars)+' (first char is a space)')\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "print('There are '+str(vocab_size)+' characters in our character set')\n",
    "\n",
    "''.join(indices_char[i] for i in idx[:70])\n",
    "\n",
    "def char2vec(c):\n",
    "    v = np.zeros(vocab_size)\n",
    "    v[char_indices[c]] = 1.\n",
    "    return v\n",
    "\n",
    "def index2vec(i):\n",
    "    v = np.zeros(vocab_size)\n",
    "    v[i] = 1.\n",
    "    return v\n",
    "\n",
    "def vec2index(v):\n",
    "    i = np.argmax(v)\n",
    "    return i\n",
    "\n",
    "def vec2char(v):\n",
    "    return indices_char[vec2index(v)]\n",
    "\n",
    "'''Form the dataset in sentences'''\n",
    "sentences_length = 10\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, 5000 - sentences_length + 1):\n",
    "    sentences.append(idx[i: i + sentences_length]) #Assume a sentence is made of X characters\n",
    "    next_chars.append(idx[i + 1: i + sentences_length + 1]) #Offset by 1 to the right for the target\n",
    "\n",
    "sentences = np.concatenate([[np.array(o)] for o in sentences[:-2]])\n",
    "next_chars = np.concatenate([[np.array(o)] for o in next_chars[:-2]])\n",
    "sentences.shape, next_chars.shape\n",
    "\n",
    "def read_sentence(idx):\n",
    "    return ''.join(indices_char[i] for i in idx)\n",
    "\n",
    "print('Here is how you can view one of the samples:')\n",
    "print('Sample input: ['+read_sentence(sentences[0])+']')\n",
    "\n",
    "print(read_sentence(sentences[2]))\n",
    "print(read_sentence(next_chars[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigma(z):\n",
    "    return np.clip(z, a_min=0, a_max=None)  # ReLU\n",
    "    #return 1./(1+np.exp(-z))  # use this for logistic\n",
    "\n",
    "def sigma_primed(y):\n",
    "    return np.clip(np.sign(y), a_min=0, a_max=1)  # Derivative of ReLU\n",
    "    #return y*(1.-y)  # use this for logistic\n",
    "\n",
    "def softmax(z):\n",
    "    ez = np.exp(z)\n",
    "    denom = np.sum(ez)\n",
    "    return ez / denom\n",
    "\n",
    "def CrossEntropy(y, t):\n",
    "    return - sum(t * np.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (a) Complete BPTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RNN():\n",
    "    \n",
    "    def __init__(self, dims, seq_length=10):\n",
    "        '''\n",
    "         Input:\n",
    "           dims is [X, H, Y], where the input has layer has X neurons, the\n",
    "                hidden layer has H neurons, and the output layer has Y neurons.\n",
    "           seq_length is how many steps to unroll the RNN through time\n",
    "                (this is the same as tau in the lecture notes)\n",
    "        '''\n",
    "        self.X, self.H, self.Y = dims\n",
    "        self.seq_length = seq_length\n",
    "        # Input layer\n",
    "        self.xs = [np.zeros(self.X) for x in range(seq_length)] # activity\n",
    "        # Hidden layer\n",
    "        self.hs = [np.zeros(self.H) for x in range(seq_length)] # activity\n",
    "        # Output layer\n",
    "        self.ys = [np.zeros(self.Y) for x in range(seq_length)] # activity\n",
    "        \n",
    "        # Connection weights\n",
    "        self.U = np.random.normal(size=[self.H, self.X])/np.sqrt(self.X) # input->hidden\n",
    "        self.W = np.random.normal(size=[self.H, self.H])/np.sqrt(self.H) # hidden->hidden\n",
    "        self.V = np.random.normal(size=[self.Y, self.H])/np.sqrt(self.H) # hidden->output\n",
    "        self.b = np.zeros(self.H) # biases for hidden nodes\n",
    "        self.c = np.zeros(self.Y) # biases for output nodes\n",
    "    \n",
    "    \n",
    "    def ForwardTT(self, seq_in):\n",
    "        '''\n",
    "         i = ForwardTT(seq_in)\n",
    "        \n",
    "         Propagates the RNN forward through time, saving all the intermediate\n",
    "         states that will be needed for backprop through time (BPTT).\n",
    "        \n",
    "         Input:\n",
    "           seq_in is a vector of indecies, with self.seq_length elements.\n",
    "        \n",
    "         Output:\n",
    "           i is the index of the character predicted to follow the input.\n",
    "         \n",
    "         This method's main purpose is to update the states of the activites\n",
    "         in the time-unrolled network.\n",
    "        '''\n",
    "        self.xs[0] = index2vec(seq_in[0]) # convert to character vector\n",
    "        \n",
    "        # Starting input current for hidden nodes\n",
    "        ss = np.dot(self.U, self.xs[0]) + self.b\n",
    "        self.hs[0] = sigma(ss)  # Activation of hidden nodes\n",
    "        \n",
    "        # Input current for output nodes\n",
    "        zs = np.dot(self.V, self.hs[0]) + self.c\n",
    "        self.ys[0] = softmax(zs)  # Activation of output nodes\n",
    "        \n",
    "        # Now process forward in time\n",
    "        for i in range(1, self.seq_length):\n",
    "            self.xs[i] = index2vec(seq_in[i])  # input vector\n",
    "            \n",
    "            # Input current for hidden nodes, including recurrent connections\n",
    "            ss = np.dot(self.U, self.xs[i]) + np.dot(self.W, self.hs[i-1]) + self.b\n",
    "            self.hs[i] = sigma(ss)  # Activation\n",
    "            \n",
    "            # Input current for output nodes\n",
    "            zs = np.dot(self.V, self.hs[i]) + self.c\n",
    "            self.ys[i] = softmax(zs)  # Activation\n",
    "            \n",
    "        # Might as well output the final state of the output\n",
    "        return vec2index(self.ys[-1])\n",
    "    \n",
    "    \n",
    "    def Generate(self, n=1):\n",
    "        '''\n",
    "         c = Generate(n=1)\n",
    "         \n",
    "         Runs the RNN from the last state after running ForwardTT, outputting\n",
    "         the next n characters.\n",
    "         \n",
    "         Input:\n",
    "           n is the number of characters you want to predict\n",
    "           \n",
    "         Output:\n",
    "           c is a string of n characters\n",
    "        '''\n",
    "        y = self.ys[-1]  # Final output of ForwardTT\n",
    "        c = vec2char(y)  # Convert it to a character string\n",
    "        h = self.hs[-1]  # Starting with last hidden state...\n",
    "        # Loop forward in time\n",
    "        # (no need to record states, since we won't be doing BPTT)\n",
    "        for nn in range(n-1):\n",
    "            x = copy.copy(y)  # Use last output as next input\n",
    "            \n",
    "            # Input current for hidden nodes\n",
    "            s = np.dot(self.U, x) + np.dot(self.W, h) + self.b\n",
    "            h = sigma(s)  # Activation\n",
    "            \n",
    "            # Input current for output nodes\n",
    "            z = np.dot(self.V, h) + self.c\n",
    "            y = softmax(z)  # Activation\n",
    "            \n",
    "            # And add the next character to our output string\n",
    "            c += vec2char(y)\n",
    "            \n",
    "        return c\n",
    "    \n",
    "    \n",
    "    def BPTT(self, seq_in, seq_out):\n",
    "        '''\n",
    "         BPTT(seq_in, seq_out)\n",
    "         \n",
    "         Performs backprop through time on one sample given by the input and\n",
    "         output sequence.\n",
    "         \n",
    "         Input:\n",
    "           seq_in is a vector of indices specifying the input sequence of\n",
    "                   characters.\n",
    "           seq_out is a vector of indices specifying the output sequence of\n",
    "                   characters. Typically, seq_out is the same as seq_in, but\n",
    "                   shifted by 1 character.\n",
    "         \n",
    "         Output:\n",
    "           None, but the connection weights and biases are updated.\n",
    "        '''\n",
    "        # Initialize gradients to zero\n",
    "        self.dEdV = np.zeros(np.shape(self.V))\n",
    "        self.dEdW = np.zeros(np.shape(self.W))\n",
    "        self.dEdU = np.zeros(np.shape(self.U))\n",
    "        self.dEdb = np.zeros(np.shape(self.b))\n",
    "        self.dEdc = np.zeros(np.shape(self.c))\n",
    "        \n",
    "    \n",
    "        # ===================\n",
    "        # ===================\n",
    "        # =  YOUR CODE HERE =\n",
    "        # ===================\n",
    "        # ===================\n",
    "        \n",
    "        dEdz = [self.ys[i] - index2vec(seq_out[i]) for i in range(self.seq_length)]\n",
    "        dEds = [0 for i in range(self.seq_length)]\n",
    "        s = [0 for i in range(self.seq_length)]\n",
    "        \n",
    "        # compute s\n",
    "        s[0] = np.dot(self.U, self.xs[0]) + self.b\n",
    "        for i in range(1, self.seq_length):\n",
    "            s[i] = np.dot(self.W, self.hs[i - 1]) + np.dot(self.U, self.xs[i]) + self.b\n",
    "        \n",
    "        # compute dEds\n",
    "        dEds[-1] = sigma_primed(s[-1]) * np.dot(self.V.T, dEdz[-1])\n",
    "        for i in range(self.seq_length - 2, -1, -1):\n",
    "            dEds[i] = sigma_primed(s[i]) * (np.dot(self.V.T, dEdz[i]) + np.dot(self.W.T, dEds[i + 1]))\n",
    "        \n",
    "        # compute dEdV\n",
    "        for i in range(self.seq_length):\n",
    "            self.dEdV += np.outer(dEdz[i], self.hs[i])\n",
    "        \n",
    "        # compute dEdU\n",
    "        for i in range(self.seq_length):\n",
    "            self.dEdU += np.outer(dEds[i], self.xs[i])\n",
    "        \n",
    "        # compute dEdW\n",
    "        for i in range(self.seq_length - 1):\n",
    "            self.dEdW += np.outer(dEds[i + 1], self.hs[i])\n",
    "        \n",
    "        # compute dEdb\n",
    "        for i in range(self.seq_length):\n",
    "            self.dEdb += dEds[i]\n",
    "\n",
    "        # compute dEdc\n",
    "        for i in range(self.seq_length):\n",
    "            self.dEdc += dEdz[i]    \n",
    "        \n",
    "    def Evaluate(self, train_in, train_out):\n",
    "        '''\n",
    "         loss = Evaluate(train_in, train_out)\n",
    "         \n",
    "         Evaluates the network on the supplied dataset.\n",
    "         \n",
    "         Input:\n",
    "           train_in is a list of input sequences (see ForwardTT for format of input)\n",
    "           train_out is the corresponding list of output sequences\n",
    "           \n",
    "         Output:\n",
    "           loss is the average cross entropy\n",
    "        '''\n",
    "        val = 0.\n",
    "        for x, t in zip(train_in, train_out):\n",
    "            self.ForwardTT(x)\n",
    "            for i in range(self.seq_length):\n",
    "                val += CrossEntropy(self.ys[i], index2vec(t[i]))\n",
    "        return val/len(train_in)\n",
    "    \n",
    "    \n",
    "    def Train(self, train_in, train_out, kappa=0.05, epochs=1):\n",
    "        '''\n",
    "         Train(train_in, train_out, kappa=0.05, epochs=1)\n",
    "         \n",
    "         Performs epochs of gradient descent, performing BPTT after each sample.\n",
    "         \n",
    "         Input:\n",
    "           train_in and train_out is the training dataset\n",
    "           kappa is the learning rate\n",
    "           epochs is the number of times to go through the dataset\n",
    "           \n",
    "         Output:\n",
    "           None, but the connection weights and biases are updated\n",
    "        '''\n",
    "        # Loop over epochs\n",
    "        for e in range(epochs):\n",
    "            \n",
    "            # Shuffle the training data\n",
    "            data_shuffled = list(zip(train_in, train_out))\n",
    "            np.random.shuffle(data_shuffled)\n",
    "\n",
    "            for x, t in data_shuffled:\n",
    "#                 print(read_sentence(x))\n",
    "#                 print(read_sentence(t))\n",
    "#                 time.sleep(10)\n",
    "                \n",
    "                self.ForwardTT(x)  # Forward through time\n",
    "                self.BPTT(x, t)    # Backprop through time\n",
    "                # Note that BPTT starts by resetting the gradients to zero.\n",
    "\n",
    "                # Apply update to connection weights and biases\n",
    "                self.V -= kappa*self.dEdV\n",
    "                self.U -= kappa*self.dEdU\n",
    "                self.W -= kappa*self.dEdW\n",
    "                self.b -= kappa*self.dEdb\n",
    "                self.c -= kappa*self.dEdc\n",
    "\n",
    "            print('Epoch '+str(e)+', Loss = '+str(self.Evaluate(train_in, train_out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (b) Create the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "net = RNN(dims = [27, 400, 27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (c) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 20.663121898591335\n",
      "Epoch 1, Loss = 17.74642826056183\n",
      "Epoch 2, Loss = 15.498805268678334\n",
      "Epoch 3, Loss = 14.005227518206434\n",
      "Epoch 4, Loss = 12.373958499458029\n",
      "Epoch 5, Loss = 11.268339718996147\n",
      "Epoch 6, Loss = 10.585846943425175\n",
      "Epoch 7, Loss = 10.035979235664657\n",
      "Epoch 8, Loss = 9.152795052629132\n",
      "Epoch 9, Loss = 8.8711732809374\n",
      "Epoch 10, Loss = 8.574602669410861\n",
      "Epoch 11, Loss = 8.315856427370166\n",
      "Epoch 12, Loss = 8.139035755968058\n",
      "Epoch 13, Loss = 7.923261172784949\n",
      "Epoch 14, Loss = 7.840028566598258\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "net.Train(sentences, next_chars, kappa = 0.001, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 17.930315917510516\n"
     ]
    }
   ],
   "source": [
    "net.Train(sentences, next_chars, kappa = 0.001, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 23.184445122949022\n"
     ]
    }
   ],
   "source": [
    "# You might opt to have more than one train command, using different\n",
    "# learning rates and numbers of epochs. Each one builds on the results\n",
    "# from the last run.\n",
    "net.Train(sentences, next_chars, kappa = 0.0005, epochs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## (d) Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:      n introduc$\n",
      "Prediction: n introduction $\n",
      "Actual:     n introduction when $\n"
     ]
    }
   ],
   "source": [
    "# A sample continuation.\n",
    "n = 38\n",
    "b = net\n",
    "b.ForwardTT(sentences[n])\n",
    "blah = read_sentence(sentences[n])\n",
    "\n",
    "print('Input:      ' + blah + '$')\n",
    "print('Prediction: ' + blah + b.Generate(5) + '$')\n",
    "print('Actual:     ' + blah + read_sentence(sentences[n+10]) + '$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harles dar$\n",
      "harles darwin iowa s$\n"
     ]
    }
   ],
   "source": [
    "# Another example.\n",
    "blah = 'harles dar'\n",
    "x = [char_indices[c] for c in blah]\n",
    "b.ForwardTT(x)\n",
    "print(blah + '$')\n",
    "print(blah + b.Generate(10) + '$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4827\n",
      "0.9675285628382442\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "cnt = 0\n",
    "for i in range(len(sentences)):\n",
    "    net.ForwardTT(sentences[i])\n",
    "    prediction = net.Generate()\n",
    "    nextchar = vec2char(index2vec(next_chars[i][-1]))\n",
    "    if prediction == nextchar:\n",
    "        cnt += 1\n",
    "\n",
    "print(cnt)\n",
    "print(cnt / len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You may include some Python code to help you.\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def ComputeGateOutput(xt, ct_1, ht_1):\n",
    "    \n",
    "    Wf = np.array([0, 8, 0, 0])\n",
    "    Wi = np.array([0, 0, 9, 0])\n",
    "    Wo = np.array([0, 0, 0, 10])\n",
    "    Wc = np.array([1, 0, 0, 0])\n",
    "\n",
    "    bf = np.array([-4])\n",
    "    bi = np.array([-4.5])\n",
    "    bo = np.array([-5])\n",
    "    bc = np.array([0])\n",
    "\n",
    "    vt = np.concatenate((ht_1, xt))\n",
    "\n",
    "    ft = sigmoid(np.dot(Wf, vt) + bf)\n",
    "    it = sigmoid(np.dot(Wi, vt) + bi)\n",
    "    ot = sigmoid(np.dot(Wo, vt) + bo)\n",
    "\n",
    "    cqt = tanh(np.dot(Wc, vt) + bc)\n",
    "    ct = ft * ct_1 + it * cqt\n",
    "    ht = ot * tanh(ct)\n",
    "    \n",
    "    return ft, it, ot, ct, ht\n",
    "\n",
    "h0 = np.array([0.05])\n",
    "c0 = np.array([-0.02])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft = [0.98201379], it = [0.01098694], ot = [0.00669285]\n",
      "Ct = [-0.01909139], ht = [-0.00012776]\n",
      "Ct-1 = [-0.02], ht-1 = [0.05], xt = [1 0 0]\n",
      "---------------------------------------------------------\n",
      "ft = [0.01798621], it = [0.98901306], ot = [0.00669285]\n",
      "Ct = [0.04904976], ht = [0.00032802]\n",
      "Ct-1 = [-0.02], ht-1 = [0.05], xt = [0 1 0]\n",
      "---------------------------------------------------------\n",
      "ft = [0.01798621], it = [0.01098694], ot = [0.99330715]\n",
      "Ct = [0.00018917], ht = [0.0001879]\n",
      "Ct-1 = [-0.02], ht-1 = [0.05], xt = [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# You can include some code, if you want.\n",
    "\n",
    "xt = np.array([1, 0, 0])\n",
    "\n",
    "ft, it, ot, ct, ht = ComputeGateOutput(xt, c0, h0)\n",
    "\n",
    "print('ft = ' + str(ft) + ', it = ' + str(it) + ', ot = ' + str(ot))\n",
    "print('Ct = ' + str(ct) + ', ht = ' + str(ht))\n",
    "print('Ct-1 = ' + str(c0) + ', ht-1 = ' + str(h0) + ', xt = ' + str(xt))\n",
    "\n",
    "xt = np.array([0, 1, 0])\n",
    "\n",
    "ft, it, ot, ct, ht = ComputeGateOutput(xt, c0, h0)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "print('ft = ' + str(ft) + ', it = ' + str(it) + ', ot = ' + str(ot))\n",
    "print('Ct = ' + str(ct) + ', ht = ' + str(ht))\n",
    "print('Ct-1 = ' + str(c0) + ', ht-1 = ' + str(h0) + ', xt = ' + str(xt))\n",
    "\n",
    "xt = np.array([0, 0, 1])\n",
    "\n",
    "ft, it, ot, ct, ht = ComputeGateOutput(xt, c0, h0)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "print('ft = ' + str(ft) + ', it = ' + str(it) + ', ot = ' + str(ot))\n",
    "print('Ct = ' + str(ct) + ', ht = ' + str(ht))\n",
    "print('Ct-1 = ' + str(c0) + ', ht-1 = ' + str(h0) + ', xt = ' + str(xt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "### (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "source": [
    "### (iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "YOUR ANSWER HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
